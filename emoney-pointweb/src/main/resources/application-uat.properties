server.port=8080
#shardingsphere配置
#spring.shardingsphere.datasource.names=db0,db1
spring.shardingsphere.datasource.names=db0
#主库
spring.shardingsphere.datasource.db0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.db0.driver-class-name=com.microsoft.sqlserver.jdbc.SQLServerDriver
spring.shardingsphere.datasource.db0.jdbc-url=jdbc:sqlserver://172.31.47.35:1433;DatabaseName=pointprod
spring.shardingsphere.datasource.db0.username=PointProdUser
spring.shardingsphere.datasource.db0.password=qU1Qp~WZh%Y3
spring.shardingsphere.datasource.db0.minimum-idle=10
spring.shardingsphere.datasource.db0.maximum-pool-size=50
spring.shardingsphere.datasource.db0.auto-commit=true
spring.shardingsphere.datasource.db0.idle-timeout=30000
spring.shardingsphere.datasource.db0.pool-name=PointProd0HikariCP
spring.shardingsphere.datasource.db0.max-lifetime=1800000
spring.shardingsphere.datasource.db0.connection-timeout=30000
spring.shardingsphere.datasource.db0.connection-test-query=SELECT 1
#从库
#spring.shardingsphere.datasource.db1.type=com.zaxxer.hikari.HikariDataSource
#spring.shardingsphere.datasource.db1.driver-class-name=com.microsoft.sqlserver.jdbc.SQLServerDriver
#spring.shardingsphere.datasource.db1.jdbc-url=jdbc:sqlserver://172.31.47.36:1433;DatabaseName=pointprod
#spring.shardingsphere.datasource.db1.username=PointProdUser
#spring.shardingsphere.datasource.db1.password=qU1Qp~WZh%Y3
#spring.shardingsphere.datasource.db1.minimum-idle=10
#spring.shardingsphere.datasource.db1.maximum-pool-size=50
#spring.shardingsphere.datasource.db1.auto-commit=true
#spring.shardingsphere.datasource.db1.idle-timeout=30000
#spring.shardingsphere.datasource.db1.pool-name=PointProd1HikariCP
#spring.shardingsphere.datasource.db1.max-lifetime=1800000
#spring.shardingsphere.datasource.db1.connection-timeout=30000
#spring.shardingsphere.datasource.db1.connection-test-query=SELECT 1
#t_point_record分表
spring.shardingsphere.sharding.tables.t_point_record.actual-data-nodes=ds0.t_point_record$->{0..31}
spring.shardingsphere.sharding.tables.t_point_record.table-strategy.inline.sharding-column=uid
spring.shardingsphere.sharding.tables.t_point_record.table-strategy.inline.algorithm-expression=t_point_record$->{uid % 32}
#_signin_record分表
spring.shardingsphere.sharding.tables.t_signin_record.actual-data-nodes=ds0.t_signin_record$->{0..31}
spring.shardingsphere.sharding.tables.t_signin_record.table-strategy.inline.sharding-column=uid
spring.shardingsphere.sharding.tables.t_signin_record.table-strategy.inline.algorithm-expression=t_signin_record$->{uid % 32}
# 读写分离
#spring.shardingsphere.sharding.master-slave-rules.ds0.master-data-source-name=db0
#spring.shardingsphere.sharding.master-slave-rules.ds0.slave-data-source-names=db1
## 从库负载均衡
spring.shardingsphere.sharding.master-slave-rules.ds0.load-balance-algorithm-type=round_robin
#是否显示sql
spring.shardingsphere.props.sql.show=false
#pagehelper插件配置
pagehelper.reasonable=false
pagehelper.support-methods-arguments=true
pagehelper.helper-dialect=sqlserver
pagehelper.params=count=countsql
#mybatis配置
mybatis.config-location=classpath:mybatis/mybatis-config.xml
mybatis.mapper-locations=classpath:mybatis/mapper/*.xml
mybatis.type-aliases-package=com.emoney.pointweb.repository.dao.entity
### resources
spring.mvc.servlet.load-on-startup=0
spring.mvc.static-path-pattern=/static/**
spring.resources.static-locations=classpath:/static/
### freemarker
spring.freemarker.templateLoaderPath=classpath:/templates/
spring.freemarker.suffix=.ftl
spring.freemarker.charset=UTF-8
spring.freemarker.request-context-attribute=request
spring.freemarker.settings.number_format=0.##########
#redis 单实例多数据源以及lettuce连接池配置
spring.redis.lettuce.pool.maxTotal=50
spring.redis.lettuce.pool.maxWaitMillis=-1
spring.redis.lettuce.pool.maxIdle=8
spring.redis.lettuce.pool.minIdle=0
#redis1
spring.redis1.database=0
spring.redis1.hostName=172.31.25.203
spring.redis1.port=6384
spring.redis1.password=
spring.redis1.timeout=600
#kafka配置
spring.kafka.bootstrap-servers=172.31.37.35:9092,172.31.37.36:9092,172.31.37.37:9092
# 发生错误后，消息重发的次数。
spring.kafka.producer.retries=0
#当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
spring.kafka.producer.batch-size=16384
# 设置生产者内存缓冲区的大小。
spring.kafka.producer.buffer-memory=33554432
# 每个Batch要存放batch.size大小的数据后，才可以发送出去
spring.kafka.producer.linger.ms=0
# 键的序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# 值的序列化方式
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
# acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
# acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
spring.kafka.producer.acks=1
# 自动提交的时间间隔
spring.kafka.consumer.auto-commit-interval=100
# 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
# latest（默认值）在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
# earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
spring.kafka.consumer.auto-offset-reset=latest
# 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
spring.kafka.consumer.enable-auto-commit=false
# 每次最大消费消息数量
spring.kafka.consumer.max-poll-records=50
# 键的反序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 值的反序列化方式
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
spring.kafka.consumer.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.request.timeout.ms=180000
#消费分组
spring.kafka.consumer.topic.group.id=pointrecordgroup
# 在侦听器容器中运行的线程数。
spring.kafka.listener.concurrency=6
#listner负责ack，每调用一次，就立即commit
spring.kafka.listener.ack-mode=manual_immediate
# 设置批量消费
# spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息
# spring.kafka.consumer.max-poll-records=50
# 消费端监听的topic不存在时，项目启动会报错(关掉)
spring.kafka.listener.missing-topics-fatal=false
pointrecord.topic=pointrecordadd
signinrecord.topic=signinrecordadd
#elasticsearch配置
spring.elasticsearch.rest.uris=172.31.25.11:9200,172.31.25.12:9200,172.31.25.13:9200
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss
spring.jackson.time-zone=GMT+8
#ds访问url
dsapiurl=http://ds.emoney.cn
#上传文件接口
fileurl=http://cmsservice.emoney.cn/comm/fileuploadEdf.ashx
#后台通行证访问接口
getuserinfourl=http://adminds.emoney.cn:83/AdminPassport/api/Safe.GetUserInfo?appid=10199&PassportId={0}
checkticketurl=http://adminds.emoney.cn:83/AdminPassport/api/Ticket.ValidateClientTicket?appid=10199&ticket={0}
#后台登录链接
loginurl=http://adminds.emoney.cn:83/AdminUserCenter/Login/Index?appUrl=http://{0}:{1}/login&FromApp=10199
#内部网关
insideGatewayUrl=http://172.31.37.202:8105
#消息通知url
swscUrl=http://swsc.emoney.cn
#webApiUrl
webApiUrl=http://webapi.emoney.cn
#积分前台url
pointfront.url=http://pre.point.emoney.cn
#WebApiEncryptKey
apiencryptkey=c049f2a1-58aa-4855-bb4a-31286aa7fda3

logisticsOrderTaskId=1390581139592318976

#邮件配置
spring.mail.host=smtp.emoney.cn
spring.mail.port=25
spring.mail.protocol=smtp
spring.mail.username=webalarm@emoney.cn
spring.mail.password=8Zrhe@WdIm
spring.mail.default-encoding=UTF-8
spring.mail.properties.mail.stmp.socketFactory.class=javax.net.ssl.SSLSocketFactory
mail.fromMail.addr=webalarm@emoney.cn
mail.toMail.addr=xueqiuyun@emoney.cn,lixiaojuan@emoney.cn,meixiaohu@emoney.cn,zhujunjie0912@emoney.cn,lipengcheng@emoney.cn

### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"
xxl.job.admin.addresses=http://172.28.1.24:8500/xxl-job-admin
### xxl-job, access token
xxl.job.accessToken=
### xxl-job executor appname
xxl.job.executor.appname=pointprodjobexecutor
### xxl-job executor registry-address: default use address to registry , otherwise use ip:port if address is null
xxl.job.executor.address=http://172.31.37.27:7151,http://172.31.37.28:7151,http://172.31.37.29:7151,http://172.31.37.30:7151,http://172.31.37.114:7151,http://172.31.37.118:7151,http://172.31.37.119:7151,http://172.31.37.120:7151
### xxl-job executor server-info
xxl.job.executor.ip=
xxl.job.executor.port=8081
### xxl-job executor log-path
xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler
### xxl-job executor log-retention-days
xxl.job.executor.logretentiondays=30

#logstash
logstash.url=172.31.25.11:4569
